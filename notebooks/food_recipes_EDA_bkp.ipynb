{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/recipes.csv', nrows=30000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RecipeInstructions'].iloc[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('../data/recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutritional_cols = ['Calories', 'FatContent', 'SaturatedFatContent', \n",
    "                   'CholesterolContent', 'SodiumContent', 'CarbohydrateContent',\n",
    "                   'FiberContent', 'SugarContent', 'ProteinContent']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"\\nNutritional Content Summary:\")\n",
    "print(df[nutritional_cols].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation heatmap for nutritional values\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df[nutritional_cols].corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation between Nutritional Values')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display unique values of RecipeCategory top 20 based on count\n",
    "df['RecipeCategory'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recipe Categories Analysis\n",
    "plt.figure(figsize=(15, 6))\n",
    "df['RecipeCategory'].value_counts().head(20).plot(kind='bar')\n",
    "plt.title('Top 20 Recipe Categories')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 20 recipe categories\n",
    "top_categories = df['RecipeCategory'].value_counts().head(20)\n",
    "\n",
    "# Create the figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Generate color gradient\n",
    "colors = sns.color_palette(\"Blues\", n_colors=len(top_categories))\n",
    "\n",
    "# Create horizontal bar plot\n",
    "bars = plt.barh(top_categories.index, top_categories.values, color=colors)\n",
    "\n",
    "# Add labels on bars\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 1000,  # Offset for better readability\n",
    "             bar.get_y() + bar.get_height()/2,\n",
    "             f'{int(width):,}',\n",
    "             va='center', fontsize=10)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Top 20 Recipe Categories', fontsize=14, pad=15)\n",
    "plt.xlabel('Count', fontsize=12)\n",
    "plt.ylabel('Recipe Category', fontsize=12)\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Remove top and right spines for a cleaner look\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 5 categories\n",
    "top_categories = df['RecipeCategory'].value_counts().head(10).index\n",
    "df_top = df[df['RecipeCategory'].isin(top_categories)]\n",
    "\n",
    "# Normalize the nutritional values for better visualization\n",
    "nutrients = ['FatContent', 'ProteinContent', 'CarbohydrateContent', 'FiberContent', 'SugarContent']\n",
    "df_normalized = df_top[nutrients].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove one dish meal, lunch, snacks, breakfast and color codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nutritional Distribution by Category\n",
    "# Stacked Bar Chart\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "nutrient_means = df_top.groupby('RecipeCategory')[nutrients].mean()\n",
    "nutrient_means_normalized = nutrient_means.apply(lambda x: x/x.sum(), axis=1)\n",
    "nutrient_means_normalized.plot(kind='barh', stacked=True)\n",
    "plt.title('Proportional Nutrient Distribution by Category')\n",
    "plt.ylabel('Recipe Category')\n",
    "plt.xlabel('Proportion of Nutrients')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nutritional Distribution by Category\n",
    "# Stacked Bar Chart\n",
    "\n",
    "# Define categories to exclude\n",
    "categories_to_exclude = ['One Dish Meal', 'Lunch/Snacks', 'Breakfast', 'Sauces', 'Chicken Breasts', 'Chicken Breast']\n",
    "\n",
    "# Filter out the excluded categories    \n",
    "df_filtered = df[~df['RecipeCategory'].isin(categories_to_exclude)]\n",
    "top_categories = df_filtered['RecipeCategory'].value_counts().head(8).index\n",
    "df_top = df_filtered[df_filtered['RecipeCategory'].isin(top_categories)]\n",
    "\n",
    "# Define color scheme\n",
    "colors = ['#FD9F6E', '#CBCE54', '#FDD526', '#A4C1F3', '#B0927A', '#C0A6CA']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "nutrient_means = df_top.groupby('RecipeCategory')[nutrients].mean()\n",
    "nutrient_means_normalized = nutrient_means.apply(lambda x: x/x.sum(), axis=1)\n",
    "ax = nutrient_means_normalized.plot(kind='barh', stacked=True, color=colors)\n",
    "# plt.title('Proportional Nutrient Distribution by Category', fontsize=18, fontweight='bold')\n",
    "plt.ylabel('Recipe Category')\n",
    "plt.xlabel('Proportion of Nutrients')\n",
    "# remove legend \n",
    "ax.legend_.remove()\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.gca().set_facecolor('#fafafa') \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingredients Analysis\n",
    "# Count number of ingredients per recipe\n",
    "df['IngredientCount'] = df['RecipeIngredientParts'].apply(lambda x: len(str(x).split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save key insights\n",
    "insights = {\n",
    "    'total_recipes': len(df),\n",
    "    'avg_rating': df['AggregatedRating'].mean(),\n",
    "    'avg_calories': df['Calories'].mean(),\n",
    "    'avg_ingredients': df['IngredientCount'].mean(),\n",
    "}\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "for key, value in insights.items():\n",
    "    print(f\"{key}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display first 10 rows of df with name, keywords, RecipeCategory, RecipeIngredientParts, RecipeInstructions, RecipeYield, PrepTime, CookTime, TotalTime, RecipeInstructions, RecipeIngredientParts\n",
    "df_temp = df[['Name', 'Keywords', 'RecipeCategory', 'RecipeIngredientParts', 'RecipeInstructions', 'RecipeYield', 'PrepTime', 'CookTime', 'TotalTime']].head(25)\n",
    "# save df to csv\n",
    "df_temp.to_csv('recipes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process ingredient\n",
    "def extract_ingredients(ingredient):\n",
    "    if pd.isna(ingredient):\n",
    "        return []\n",
    "    # Clean the string and split into ingredients\n",
    "    ingredients = ingredient.replace('c(', '').replace(')', '').replace('\"', '').split(',')\n",
    "    return [ingredient.strip().lower() for ingredient in ingredients]\n",
    "\n",
    "# Extract and count all ingredient\n",
    "all_ingredients = []\n",
    "for ingredient in df['RecipeIngredientParts'].dropna():\n",
    "    all_ingredients.extend(extract_ingredients(ingredient))\n",
    "\n",
    "# Count ingredients and get top 20\n",
    "ingredient_counts = pd.Series(all_ingredients).value_counts().head(20)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create horizontal bar chart with color gradient\n",
    "colors = sns.color_palette(\"RdYlBu_r\", n_colors=len(ingredient_counts))\n",
    "bars = plt.barh(range(len(ingredient_counts)), ingredient_counts.values, color=colors)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Top 20 Recipe ingredients', fontsize=14, pad=20)\n",
    "plt.xlabel('Count', fontsize=12)\n",
    "plt.ylabel('Ingredients', fontsize=12)\n",
    "\n",
    "# Add value labels on the bars\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 100,  \n",
    "             bar.get_y() + bar.get_height()/2,\n",
    "             f'{int(width):,}',\n",
    "             va='center',\n",
    "             fontsize=10)\n",
    "\n",
    "# Set y-tick labels\n",
    "plt.yticks(range(len(ingredient_counts)), ingredient_counts.index)\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nIngredient Statistics:\")\n",
    "print(f\"Total Unique ingredient: {len(pd.Series(all_ingredients).unique()):,}\")\n",
    "print(f\"Total ingredient Occurrences: {len(all_ingredients):,}\")\n",
    "\n",
    "# Print top ingredient combinations\n",
    "print(\"\\n🔍 Top 5 Most Common Ingredients:\")\n",
    "for idx, (ingredient, count) in enumerate(ingredient_counts.head(20).items(), 1):\n",
    "    print(f\"{idx}. {ingredient.title()}: {count:,} recipes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ingredient(ingredient):\n",
    "    \"\"\"Normalize ingredient names by combining similar ingredients\"\"\"\n",
    "    ingredient = ingredient.lower().strip()\n",
    "    \n",
    "    # Dictionary of ingredient mappings\n",
    "    ingredient_mappings = {\n",
    "        # Eggs\n",
    "        'eggs': 'egg',\n",
    "        'egg whites': 'egg',\n",
    "        'egg white': 'egg',\n",
    "        'egg yolks': 'egg',\n",
    "        'egg yolk': 'egg',\n",
    "        'raw egg': 'egg',\n",
    "        'egg substitute': 'egg',\n",
    "        'egg beaters': 'egg',\n",
    "        \n",
    "        # Sugar\n",
    "        'brown sugar': 'sugar',\n",
    "        'white sugar': 'sugar',\n",
    "        'granulated sugar': 'sugar',\n",
    "        'powdered sugar': 'sugar',\n",
    "        'caster sugar': 'sugar',\n",
    "        'confectioners sugar': 'sugar',\n",
    "        'demerara sugar': 'sugar',\n",
    "        'light demerara sugar': 'sugar',\n",
    "        \n",
    "        # Salt\n",
    "        'sea salt': 'salt',\n",
    "        'kosher salt': 'salt',\n",
    "        \n",
    "        # Flour \n",
    "        'all-purpose flour': 'flour',\n",
    "        'all purpose flour': 'flour',\n",
    "        'unbleached all-purpose flour': 'flour',\n",
    "        'unbleached all purpose flour': 'flour',\n",
    "        'self-rising flour': 'flour',\n",
    "        'plain flour': 'flour',\n",
    "        'wheat flour': 'flour',\n",
    "        \n",
    "        # Oil\n",
    "        'vegetable oil': 'oil',\n",
    "        'olive oil': 'oil',\n",
    "        'spanish olive oil': 'oil',\n",
    "        'walnut oil': 'oil',\n",
    "        'canola oil': 'oil',\n",
    "        'extra virgin olive oil': 'oil',\n",
    "        'coconut oil': 'oil',\n",
    "        \n",
    "        # Butter\n",
    "        'unsalted butter': 'butter',\n",
    "        'salted butter': 'butter',\n",
    "        'melted butter': 'butter',\n",
    "        'sweet butter': 'butter',\n",
    "    }\n",
    "    \n",
    "    # Return normalized ingredient name\n",
    "    return ingredient_mappings.get(ingredient, ingredient)\n",
    "\n",
    "def extract_ingredients(ingredient_str):\n",
    "    \"\"\"Extract and normalize ingredients from string\"\"\"\n",
    "    if pd.isna(ingredient_str):\n",
    "        return []\n",
    "    # Clean the string and split into ingredients\n",
    "    ingredients = ingredient_str.replace('c(', '').replace(')', '').replace('\"', '').split(',')\n",
    "    return [normalize_ingredient(ingredient.strip().lower()) for ingredient in ingredients]\n",
    "\n",
    "# Extract and count all ingredients\n",
    "all_ingredients = []\n",
    "for ingredient in df['RecipeIngredientParts'].dropna():\n",
    "    all_ingredients.extend(extract_ingredients(ingredient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all ingredients to csv\n",
    "df_ingredients = pd.DataFrame(all_ingredients, columns=['ingredients'])\n",
    "df_ingredients.to_csv('ingredients.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count ingredients and get top 20\n",
    "ingredient_counts = pd.Series(all_ingredients).value_counts().head(20)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create horizontal bar chart with custom color palette\n",
    "colors = sns.color_palette(\"RdYlBu_r\", n_colors=len(ingredient_counts))\n",
    "bars = plt.barh(range(len(ingredient_counts)), ingredient_counts.values, color=colors)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Top 20 Recipe Ingredients (Normalized)', fontsize=14, pad=20)\n",
    "plt.xlabel('Count', fontsize=12)\n",
    "plt.ylabel('Ingredients', fontsize=12)\n",
    "\n",
    "# Add value labels on the bars\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 100,  \n",
    "             bar.get_y() + bar.get_height()/2,\n",
    "             f'{int(width):,}',\n",
    "             va='center',\n",
    "             fontsize=10)\n",
    "\n",
    "# Set y-tick labels\n",
    "plt.yticks(range(len(ingredient_counts)), ingredient_counts.index)\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics with emoji\n",
    "print(\"\\n📊 Ingredient Statistics:\")\n",
    "print(f\"Total Unique Ingredients: {len(pd.Series(all_ingredients).unique()):,}\")\n",
    "print(f\"Total Ingredient Occurrences: {len(all_ingredients):,}\")\n",
    "print(f\"Most Common Ingredient: {ingredient_counts.index[0]} ({ingredient_counts.values[0]:,} occurrences)\")\n",
    "\n",
    "# Print top ingredient combinations\n",
    "print(\"\\n🔍 Top 5 Most Common Ingredients:\")\n",
    "for idx, (ingredient, count) in enumerate(ingredient_counts.head().items(), 1):\n",
    "    print(f\"{idx}. {ingredient.title()}: {count:,} recipes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('../data/recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['Calories', 'FatContent', 'SaturatedFatContent', \n",
    "                    'CholesterolContent', 'SodiumContent', 'CarbohydrateContent',\n",
    "                    'FiberContent', 'SugarContent', 'ProteinContent']\n",
    "\n",
    "# Check which rows have all zeros in numeric columns\n",
    "all_zeros = (df[numeric_columns] == 0).all(axis=1)\n",
    "zero_nutrition_rows = df[all_zeros]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(f\"\\nAnalysis of Zero Nutritional Values:\")\n",
    "print(f\"Total rows with all nutritional values = 0: {len(zero_nutrition_rows)} ({(len(zero_nutrition_rows)/len(df)*100):.2f}%)\")\n",
    "\n",
    "# Display sample of these rows\n",
    "print(\"\\nSample of recipes with zero nutritional values:\")\n",
    "print(zero_nutrition_rows[['Name', 'RecipeCategory'] + numeric_columns].head())\n",
    "\n",
    "# Save these recipes to investigate\n",
    "# zero_nutrition_rows.to_csv('zero_nutrition_recipes.csv', index=False)\n",
    "\n",
    "# Additional analysis of these rows\n",
    "print(\"\\nCategories with zero nutritional values:\")\n",
    "print(zero_nutrition_rows['RecipeCategory'].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with all zeros and create new dataframe\n",
    "df_clean = df[~all_zeros].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a copy to avoid modifying original data\n",
    "# df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Time-related columns\n",
    "\n",
    "def convert_duration(duration_str):\n",
    "    \"\"\"Convert ISO 8601 duration format to minutes\"\"\"\n",
    "    if pd.isna(duration_str):\n",
    "        return np.nan\n",
    "        \n",
    "    try:\n",
    "        # Remove 'PT' prefix and initialize variables\n",
    "        duration_str = str(duration_str).replace('PT', '')\n",
    "        hours = 0\n",
    "        minutes = 0\n",
    "        \n",
    "        # Find hours\n",
    "        hour_match = re.search(r'(\\d+)H', duration_str)\n",
    "        if hour_match:\n",
    "            hours = int(hour_match.group(1))\n",
    "        \n",
    "        # Find minutes\n",
    "        minute_match = re.search(r'(\\d+)M', duration_str)\n",
    "        if minute_match:\n",
    "            minutes = int(minute_match.group(1))\n",
    "        \n",
    "        total_minutes = hours * 60 + minutes\n",
    "        return total_minutes if total_minutes > 0 else np.nan\n",
    "        \n",
    "    except (ValueError, AttributeError):\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time columns to minutes\n",
    "time_columns = ['CookTime', 'PrepTime', 'TotalTime']\n",
    "for col in time_columns:\n",
    "    df_clean[f'New_{col}_Minutes'] = df_clean[col].apply(convert_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[['CookTime', 'PrepTime', 'TotalTime', 'New_CookTime_Minutes', 'New_PrepTime_Minutes', 'New_TotalTime_Minutes']].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date formatting\n",
    "\n",
    "df_clean['DatePublished'] = pd.to_datetime(df_clean['DatePublished'])\n",
    "df_clean['PublishYear'] = df_clean['DatePublished'].dt.year\n",
    "df_clean['PublishMonth'] = df_clean['DatePublished'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text columns\n",
    "text_columns = ['Name', 'Description', 'RecipeCategory', 'AuthorName']\n",
    "for col in text_columns:\n",
    "    df_clean[col] = df_clean[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Keywords\n",
    "def clean_keywords(keywords_str):\n",
    "    if pd.isna(keywords_str):\n",
    "        return []\n",
    "    # Remove c() and split\n",
    "    keywords = keywords_str.replace('c(', '').replace(')', '').replace('\"', '').split(',')\n",
    "    return [k.strip() for k in keywords if k.strip()]\n",
    "\n",
    "df_clean['New_Keywords_List'] = df_clean['Keywords'].apply(clean_keywords)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Ingredients\n",
    "def clean_ingredients(ingredients_str):\n",
    "    if pd.isna(ingredients_str):\n",
    "        return []\n",
    "    ingredients = ingredients_str.replace('c(', '').replace(')', '').replace('\"', '').split(',')\n",
    "    return [ing.strip() for ing in ingredients if ing.strip()]\n",
    "\n",
    "df_clean['New_Ingredients_List'] = df_clean['RecipeIngredientParts'].apply(clean_ingredients)\n",
    "df_clean['New_Quantities_List'] = df_clean['RecipeIngredientQuantities'].apply(clean_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Instructions\n",
    "def clean_instructions(instructions_str):\n",
    "    if pd.isna(instructions_str):\n",
    "        return []\n",
    "    instructions = instructions_str.replace('c(', '').replace(')', '').replace('\"', '').split('.,')\n",
    "    return [instr.strip() + '.' for instr in instructions if instr.strip()]\n",
    "\n",
    "df_clean['New_Instructions_List'] = df_clean['RecipeInstructions'].apply(clean_instructions)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = None\n",
    "# pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find df_clean where recipe id = 39\n",
    "# df_clean[df_clean['RecipeId'] == 39]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format numeric columns\n",
    "numeric_columns = ['Calories', 'FatContent', 'SaturatedFatContent', \n",
    "                    'CholesterolContent', 'SodiumContent', 'CarbohydrateContent',\n",
    "                    'FiberContent', 'SugarContent', 'ProteinContent']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric_columns].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[numeric_columns].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 50k records randomly from df_cleaned\n",
    "# df_5k = df_clean.sample(n=5000, random_state=42)  # random_state for reproducibility\n",
    "\n",
    "# # Save to CSV file\n",
    "# output_path = 'recipes_5k.csv'\n",
    "# df_5k.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for partially missing nutritional information\n",
    "# def analyze_zero_nutrients(df_clean):\n",
    "#     zero_counts = {}\n",
    "#     for col in numeric_columns:\n",
    "#         zero_counts[col] = (df_clean[col] == 0).sum()\n",
    "    \n",
    "#     print(\"\\n Count of zero values for each nutrient:\")\n",
    "#     for col, count in zero_counts.items():\n",
    "#         percentage = (count/len(df_clean)*100)\n",
    "#         print(f\"{col}: {count} zeros ({percentage:.2f}%)\")\n",
    "    \n",
    "#     # Check for suspicious patterns\n",
    "#     partial_zeros = df_clean[df_clean[numeric_columns].apply(lambda x: (x == 0).any() & (x != 0).any(), axis=1)]\n",
    "#     print(f\"\\nRows with some (but not all) zero values: {len(partial_zeros)}\")\n",
    "    \n",
    "#     return partial_zeros\n",
    "\n",
    "# partial_zeros = analyze_zero_nutrients(df_clean)\n",
    "\n",
    "# # Display sample of partial zero rows\n",
    "# print(\"Sample of recipes with partial zero nutritional values:\")\n",
    "# print(partial_zeros[['Name', 'RecipeCategory'] + numeric_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean['Name'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all duplicated names\n",
    "# df[df['Name'].duplicated(keep=False)].sort_values(by='Name')\n",
    "\n",
    "\n",
    "# Find duplicates and show first 10 records\n",
    "duplicated_recipes = df_clean[df_clean['Name'].duplicated(keep=False)].sort_values(by='Name').head(10)\n",
    "\n",
    "# Display the results in a more readable format\n",
    "print(f\"Sample of Duplicated Recipe Names:\")\n",
    "\n",
    "print(duplicated_recipes[['Name', 'AuthorName', 'RecipeCategory', 'AggregatedRating', 'ReviewCount', 'Calories']+numeric_columns].to_string())\n",
    "\n",
    "print(f\"\\nTotal number of recipes with duplicate names: {len(df[df['Name'].duplicated(keep=False)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Near duplicates, convert all names to lowercase and strip whitespace:\n",
    "df_clean['clean_name'] = df_clean['Name'].str.lower().str.strip()\n",
    "\n",
    "df_duplicates = df_clean[df_clean['clean_name'].duplicated(keep=False)].sort_values(by='clean_name')\n",
    "# show df_duplicates\n",
    "df_duplicates.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show df_duplicates with all columns\n",
    "df_duplicates[df_clean.columns].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create clean name column\n",
    "df_clean['clean_name'] = df_clean['Name'].str.lower().str.strip()\n",
    "\n",
    "# Check duplicates across multiple relevant columns\n",
    "columns_to_check = [\n",
    "    'clean_name',\n",
    "    'Calories',\n",
    "    'FatContent',\n",
    "    'SaturatedFatContent',\n",
    "    'CholesterolContent',\n",
    "    'SodiumContent',\n",
    "    'CarbohydrateContent',\n",
    "    'FiberContent',\n",
    "    'SugarContent',\n",
    "    'ProteinContent',\n",
    "    'RecipeCategory'\n",
    "]\n",
    "\n",
    "# Find duplicates across all specified columns\n",
    "duplicates = df_clean[df_clean.duplicated(subset=columns_to_check, keep=False)].sort_values(by='clean_name')\n",
    "\n",
    "# Display summary\n",
    "print(f\"Duplicate Analysis:\")\n",
    "print(f\"Total number of duplicate records: {len(duplicates)}\")\n",
    "print(f\"Number of unique recipes that have duplicates: {len(duplicates['clean_name'].unique())}\")\n",
    "\n",
    "# Show sample of duplicates with relevant columns\n",
    "print(\"\\nSample of Duplicate Records (showing different RecipeIds but same content):\")\n",
    "print(\"=\" * 100)\n",
    "sample_cols = ['RecipeId', 'Name', 'AuthorName', 'RecipeCategory', 'Calories', 'ReviewCount']\n",
    "print(duplicates[sample_cols].head(10).to_string())\n",
    "\n",
    "# Group by clean name to see how many duplicates each recipe has\n",
    "duplicate_counts = duplicates.groupby('clean_name').size().sort_values(ascending=False)\n",
    "print(\"\\nTop 10 Most Duplicated Recipes:\")\n",
    "print(duplicate_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns that were processed or are no longer needed\n",
    "columns_to_drop = [\n",
    "    'clean_name',  # processed version of Name\n",
    "    'IngredientEmbedding',  # if this was processed into vectors\n",
    "    'Images',  # if you've already extracted main image\n",
    "    'Keywords',  # if you've processed this into a list\n",
    "    'RecipeIngredientQuantities',  # if you've already processed ingredients\n",
    "    'RecipeIngredientParts',  # if you've already processed ingredients\n",
    "    'RecipeInstructions',  # if you've already processed instructions\n",
    "    'CookTime',  # if you've converted to minutes\n",
    "    'PrepTime',  # if you've converted to minutes\n",
    "    'TotalTime',  # if you've converted to minutes\n",
    "]\n",
    "\n",
    "# Show current columns\n",
    "print(\"Current columns in df_clean:\")\n",
    "print(df_clean.columns.tolist())\n",
    "print(f\"\\nTotal columns: {len(df_clean.columns)}\")\n",
    "\n",
    "# Drop the columns and create new dataframe\n",
    "df_clean_reduced = df_clean.drop(columns=[col for col in columns_to_drop if col in df_clean.columns])\n",
    "\n",
    "# Show remaining columns\n",
    "print(\"\\nRemaining columns after dropping processed ones:\")\n",
    "print(df_clean_reduced.columns.tolist())\n",
    "print(f\"\\nRemaining columns: {len(df_clean_reduced.columns)}\")\n",
    "\n",
    "# Show what was dropped\n",
    "dropped_cols = [col for col in columns_to_drop if col in df_clean.columns]\n",
    "print(\"\\nColumns that were dropped:\")\n",
    "print(dropped_cols)\n",
    "\n",
    "# Save the reduced dataframe if needed\n",
    "df_clean = df_clean_reduced.copy()\n",
    "print(\"\\n✅ Dataframe updated with reduced columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Clean CSV for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df_clean.to_csv('df_clean_reduced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load both dataframes\n",
    "df_clean_reduced = pd.read_csv('df_clean_reduced.csv', nrows=20000)  # Reduced df_clean\n",
    "# df_original = pd.read_csv('data/df_clean.csv')  # Original df_clean with ingredient information\n",
    "\n",
    "# First, let's explode the ingredients list to get individual ingredients\n",
    "all_ingredients = df['RecipeIngredientParts'].str.strip('[]').str.split(',').explode()\n",
    "\n",
    "# Clean the ingredients (remove quotes, spaces, etc.)\n",
    "all_ingredients = all_ingredients.str.strip().str.strip('\"\\'').str.lower()\n",
    "\n",
    "# Count the frequency of each ingredient\n",
    "ingredient_counts = all_ingredients.value_counts()\n",
    "\n",
    "# Get top 20 ingredients\n",
    "top_20_ingredients = ingredient_counts.head(20)\n",
    "\n",
    "# Create a more readable display with enhanced formatting\n",
    "print(\"Top 20 Most Common Ingredients in Recipes\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Rank':<6}{'Ingredient':<35}{'Count':>10}{'Percentage':>12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "total_recipes = len(df_clean_reduced)\n",
    "for idx, (ingredient, count) in enumerate(top_20_ingredients.items(), 1):\n",
    "    percentage = (count / total_recipes) * 100\n",
    "    print(f\"{idx:<6}{ingredient:<35}{count:>10,}{percentage:>11.1f}%\")\n",
    "\n",
    "# Create an enhanced visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = sns.color_palette(\"husl\", n_colors=20)\n",
    "bars = sns.barplot(x=top_20_ingredients.values, \n",
    "                  y=top_20_ingredients.index,\n",
    "                  palette=colors)\n",
    "plt.title('Top 20 Most Common Ingredients in Recipes', pad=20, fontsize=14)\n",
    "plt.xlabel('Number of Recipes', fontsize=12)\n",
    "plt.ylabel('Ingredients', fontsize=12)\n",
    "for i, v in enumerate(top_20_ingredients.values):\n",
    "    bars.text(v, i, f' {v:,}', va='center', fontsize=10)\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_ingredient_bigrams_no_nltk(df, column_name='New_Ingredients_List', top_n=20):\n",
    "    \"\"\"\n",
    "    Plot the top N ingredient bigrams without using NLTK.\n",
    "    \"\"\"\n",
    "    # Custom stop words\n",
    "    stop_words = {'and', 'the', 'of', 'with', 'for', 'to', 'in', 'a', 'an', 'or', \n",
    "                 'as', 'at', 'by', 'from', 'into', 'on', 'that', 'this'}\n",
    "    \n",
    "    all_ingredients = []\n",
    "    for ingredient_list in df[column_name]:\n",
    "        if isinstance(ingredient_list, list):\n",
    "            for ing in ingredient_list:\n",
    "                # Simple cleaning\n",
    "                words = [word.lower().strip(\".,!?()\") for word in ing.split()]\n",
    "                clean_ing = ' '.join([word for word in words \n",
    "                                     if word not in stop_words and len(word) > 2])\n",
    "                if clean_ing:\n",
    "                    all_ingredients.append(clean_ing)\n",
    "    \n",
    "    # Generate bigrams manually\n",
    "    bigram_counts = {}\n",
    "    for i in range(len(all_ingredients)-1):\n",
    "        bigram = (all_ingredients[i], all_ingredients[i+1])\n",
    "        bigram_counts[bigram] = bigram_counts.get(bigram, 0) + 1\n",
    "    \n",
    "    # Get top bigrams\n",
    "    top_bigrams = sorted(bigram_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh([' '.join(bigram) for bigram, count in top_bigrams],\n",
    "             [count for bigram, count in top_bigrams],\n",
    "             color='lightgreen')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Ingredient Bigrams')\n",
    "    plt.title(f'Top {top_n} Most Common Ingredient Bigrams')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_ingredient_bigrams_no_nltk(df_clean, column_name='New_Ingredients_List', top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ingredient_network(df, column_name='New_Ingredients_List', top_n=15):\n",
    "    \"\"\"\n",
    "    Plot ingredient relationships as a clean network graph with standardized ingredient names.\n",
    "    \"\"\"\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    from collections import Counter\n",
    "\n",
    "    # Dictionary of ingredient mappings (provided)\n",
    "    ingredient_mappings = {\n",
    "        # Eggs\n",
    "        'eggs': 'egg',\n",
    "        'egg whites': 'egg',\n",
    "        'egg white': 'egg',\n",
    "        'egg yolks': 'egg',\n",
    "        'egg yolk': 'egg',\n",
    "        'raw egg': 'egg',\n",
    "        'egg substitute': 'egg',\n",
    "        'egg beaters': 'egg',\n",
    "        \n",
    "        # Sugar\n",
    "        'brown sugar': 'sugar',\n",
    "        'white sugar': 'sugar',\n",
    "        'granulated sugar': 'sugar',\n",
    "        'powdered sugar': 'sugar',\n",
    "        'caster sugar': 'sugar',\n",
    "        'confectioners sugar': 'sugar',\n",
    "        'demerara sugar': 'sugar',\n",
    "        'light demerara sugar': 'sugar',\n",
    "        \n",
    "        # Salt\n",
    "        'sea salt': 'salt',\n",
    "        'kosher salt': 'salt',\n",
    "        \n",
    "        # Flour \n",
    "        'all-purpose flour': 'flour',\n",
    "        'all purpose flour': 'flour',\n",
    "        'unbleached all-purpose flour': 'flour',\n",
    "        'unbleached all purpose flour': 'flour',\n",
    "        'self-rising flour': 'flour',\n",
    "        'plain flour': 'flour',\n",
    "        'wheat flour': 'flour',\n",
    "        \n",
    "        # Oil\n",
    "        'vegetable oil': 'oil',\n",
    "        'olive oil': 'oil',\n",
    "        'spanish olive oil': 'oil',\n",
    "        'walnut oil': 'oil',\n",
    "        'canola oil': 'oil',\n",
    "        'extra virgin olive oil': 'oil',\n",
    "        'coconut oil': 'oil',\n",
    "        \n",
    "        # Butter\n",
    "        'unsalted butter': 'butter',\n",
    "        'salted butter': 'butter',\n",
    "        'melted butter': 'butter',\n",
    "        'sweet butter': 'butter',\n",
    "    }\n",
    "\n",
    "    # Custom stop words and cleaning\n",
    "    stop_words = {'and', 'the', 'of', 'with', 'for', 'to', 'in', 'a', 'an', 'or', \n",
    "                 'as', 'at', 'by', 'from', 'into', 'on', 'that', 'this', 'fresh', 'dried'}\n",
    "    \n",
    "    def clean_and_map_ingredient(ing):\n",
    "        \"\"\"Clean ingredient and apply mapping to standardized names\"\"\"\n",
    "        if not isinstance(ing, str):\n",
    "            return None\n",
    "            \n",
    "        # Basic cleaning\n",
    "        words = [word.lower().strip(\".,!?()%\") for word in ing.split()]\n",
    "        clean_ing = ' '.join([word for word in words \n",
    "                            if word not in stop_words and len(word) > 2])\n",
    "        \n",
    "        # Apply mapping if exists, otherwise return cleaned version\n",
    "        return ingredient_mappings.get(clean_ing, clean_ing)\n",
    "\n",
    "    # Process ingredients with cleaning and mapping\n",
    "    all_ingredients = []\n",
    "    for ingredient_list in df[column_name]:\n",
    "        if isinstance(ingredient_list, str):\n",
    "            try:\n",
    "                ingredients = eval(ingredient_list)\n",
    "            except:\n",
    "                ingredients = ingredient_list.split(',')\n",
    "        else:\n",
    "            ingredients = ingredient_list\n",
    "            \n",
    "        for ing in ingredients:\n",
    "            mapped_ing = clean_and_map_ingredient(ing)\n",
    "            if mapped_ing and mapped_ing not in {'', ' '}:\n",
    "                all_ingredients.append(mapped_ing)\n",
    "    \n",
    "    # Count ingredient frequencies\n",
    "    ingredient_counts = Counter(all_ingredients)\n",
    "    \n",
    "    # Generate bigrams and count co-occurrences\n",
    "    bigram_counts = Counter()\n",
    "    for i in range(len(all_ingredients)-1):\n",
    "        ing1, ing2 = all_ingredients[i], all_ingredients[i+1]\n",
    "        if ing1 != ing2:  # Skip self-pairs\n",
    "            bigram = tuple(sorted((ing1, ing2)))\n",
    "            bigram_counts[bigram] += 1\n",
    "    \n",
    "    # Create network graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Get top ingredients by frequency\n",
    "    top_ingredients = [ing for ing, count in ingredient_counts.most_common(top_n)]\n",
    "    \n",
    "    # Add nodes and edges (only between top ingredients)\n",
    "    for (ing1, ing2), weight in bigram_counts.items():\n",
    "        if ing1 in top_ingredients and ing2 in top_ingredients and weight > 2:\n",
    "            G.add_edge(ing1, ing2, weight=weight)\n",
    "    \n",
    "    # Only keep nodes that have edges\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    \n",
    "    # Set up the plot with professional styling\n",
    "    plt.figure(figsize=(18, 12), facecolor='white')\n",
    "    \n",
    "    # Calculate layout with better spacing\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=100, seed=42)\n",
    "    \n",
    "    # Custom color gradient\n",
    "    cmap = LinearSegmentedColormap.from_list('ingredient_cmap', ['#d6eb6e', '#d6eb6e'])\n",
    "    \n",
    "    # Node sizes based on frequency (log scale for better visibility)\n",
    "    max_count = max(ingredient_counts.values())\n",
    "    node_sizes = [300 + 3000 * (ingredient_counts[node]/max_count) for node in G.nodes()]\n",
    "    \n",
    "    # Node colors based on centrality (importance in network)\n",
    "    centrality = nx.degree_centrality(G)\n",
    "    node_colors = [cmap(centrality[node]) for node in G.nodes()]\n",
    "    \n",
    "    # Edge widths based on co-occurrence frequency\n",
    "    if bigram_counts:\n",
    "        max_weight = max(bigram_counts.values())\n",
    "        edge_weights = [2 + 3 * G[u][v]['weight']/max_weight for u,v in G.edges()]\n",
    "    else:\n",
    "        edge_weights = [2] * len(G.edges())\n",
    "    \n",
    "    # Draw the network with improved styling\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        node_size=node_sizes,\n",
    "        node_color=node_colors,\n",
    "        alpha=0.9,\n",
    "        edgecolors='white',\n",
    "        linewidths=1.5\n",
    "    )\n",
    "    \n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos,\n",
    "        width=edge_weights,\n",
    "        alpha=0.3,\n",
    "        edge_color='black'\n",
    "    )\n",
    "    \n",
    "    # Label only the most important nodes to reduce clutter\n",
    "    important_nodes = [node for node in G.nodes() if centrality[node] > 0.1]\n",
    "    labels = {node: node.replace(' ', '\\n') for node in important_nodes}\n",
    "    \n",
    "    nx.draw_networkx_labels(\n",
    "        G, pos,\n",
    "        labels=labels,\n",
    "        font_size=14,\n",
    "        font_family='sans-serif',\n",
    "        font_weight='bold',\n",
    "        alpha=1,\n",
    "    )\n",
    "    \n",
    "    # Add title and adjust layout\n",
    "    # plt.title('Ingredient Co-occurrence Network (Standardized Names)', fontsize=22, fontweight='bold', pad=20)\n",
    "    plt.axis('off')\n",
    "    plt.gca().set_facecolor('#fafafa') \n",
    "    # Add legend for node size/color\n",
    "    plt.text(0.95, 0.05, \n",
    "            #  \"Node size ≈ Ingredient frequency\\nNode color ≈ Network importance\",\n",
    "            \"Node size ≈ Ingredient frequency\",\n",
    "             transform=plt.gca().transAxes,\n",
    "             ha='right', va='bottom',\n",
    "             bbox=dict(facecolor='white', alpha=0.7), \n",
    "             fontsize=16\n",
    "             )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ingredient_network(df_clean, top_n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # !pip install holoviews hvplot bokeh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "\n",
    "hv.extension('bokeh')  # Enable Holoviews with Bokeh backend\n",
    "\n",
    "# Generate Co-occurrence Pairs\n",
    "ingredient_pairs = []\n",
    "for ingredients in df_clean[\"New_Ingredients_List\"]:\n",
    "    unique_ingredients = sorted(set(ingredients))  # Remove duplicates within a recipe\n",
    "    ingredient_pairs.extend(itertools.combinations(unique_ingredients, 2))\n",
    "\n",
    "# Count occurrences of each ingredient pair\n",
    "from collections import Counter\n",
    "pair_counts = Counter(ingredient_pairs)\n",
    "\n",
    "# Get top N most frequent pairs\n",
    "top_pairs = pair_counts.most_common(50)\n",
    "\n",
    "# Convert pairs into a DataFrame for Holoviews Chord Diagram\n",
    "data = [(pair[0], pair[1], count) for pair, count in top_pairs]\n",
    "df_pairs = pd.DataFrame(data, columns=[\"Source\", \"Target\", \"Weight\"])\n",
    "\n",
    "title_html = pn.pane.HTML(\n",
    "    \"<h3 style='color:#FF6347; font-size:16px; text-align:center;'>Ingredient Co-occurrence Chord Diagram</h3>\",\n",
    "    width=600\n",
    ")\n",
    "\n",
    "chord = hv.Chord(df_pairs).opts(\n",
    "    opts.Chord(\n",
    "        cmap='Category20', \n",
    "        edge_cmap='viridis', \n",
    "        edge_color='Weight',\n",
    "        labels='index', \n",
    "        node_color='index',\n",
    "        height=600, width=600,\n",
    "        \n",
    "    )\n",
    ")\n",
    "\n",
    "# save the chord diagram\n",
    "hv.save(chord, 'chord_diagram.html')\n",
    "\n",
    "# Display\n",
    "chord\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
